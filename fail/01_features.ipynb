{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a48b95-388f-4b23-9b0a-29744100a42c",
   "metadata": {},
   "source": [
    "# Extract features\n",
    "\n",
    "## Choice of model for transfer learning\n",
    "\n",
    "The Inception v3 and MobileNet v2 are both up to the task of extracting high-level features from the data. The TF Hub implementations of MobileNet and of Inception have been trained on the ILSVRC-2012-CLS \"ImageNet\" data set, and have the same signature for feature vectors.\n",
    "\n",
    "The MobileNet v2 is optimized for mobile applications. Since I'm not building a mobile application, I chose the Inception v3 model. This model expects slightly larger input images and yields 2048 features for each image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0385bab5-3b6c-4b8e-ad24-3e4def0df986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 23:10:43.161841: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-11 23:10:43.169897: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736633443.178941   13510 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736633443.181670   13510 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-11 23:10:43.191154: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/atroncos/workspace/oa_venv/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Tensorflow version: 2.18.0, TF hub version: 0.16.1\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf \n",
    "tf.disable_v2_behavior()\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "print('Tensorflow version: {}, TF hub version: {}'.format(tf.__version__, hub.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d674a0-6342-4563-a760-7a4914e6c136",
   "metadata": {},
   "source": [
    "## Create a network\n",
    "\n",
    "Create a network for extracting high-level features from image data, by loading the chosen pre-trained model from TF Hub. The network has a placeholder for the image input and an output node. Initialize the network.\n",
    "\n",
    "\n",
    "Migrate this\n",
    "* https://www.tensorflow.org/hub/migration_tf2\n",
    "* https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_image_retraining.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "400603c4-0ec3-42f0-ad47-c8d410512164",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_hub' has no attribute 'load_module_spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m img_graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# pretrained network Inception v3\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     module_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://tfhub.dev/google/imagenet/inception_v3/feature_vector/1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m     module_spec \u001b[38;5;241m=\u001b[39m \u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_module_spec\u001b[49m(module_url)\n\u001b[1;32m      7\u001b[0m     height, width \u001b[38;5;241m=\u001b[39m hub\u001b[38;5;241m.\u001b[39mget_expected_image_size(module_spec)\n\u001b[1;32m      8\u001b[0m     feature_extractor \u001b[38;5;241m=\u001b[39m hub\u001b[38;5;241m.\u001b[39mModule(module_spec)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_hub' has no attribute 'load_module_spec'"
     ]
    }
   ],
   "source": [
    "img_graph = tf.Graph()\n",
    "\n",
    "with img_graph.as_default():\n",
    "    # pretrained network Inception v3\n",
    "    module_url = 'https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1'\n",
    "    module_spec = hub.load_module_spec(module_url)\n",
    "    height, width = hub.get_expected_image_size(module_spec)\n",
    "    feature_extractor = hub.Module(module_spec)\n",
    "    \n",
    "    # expected size of input images\n",
    "    height, width = 299, 299\n",
    "    \n",
    "    # placeholder for input\n",
    "    input_imgs = tf.placeholder(dtype=tf.float32, shape=[None, height, width, 3])\n",
    "    \n",
    "    # node that represents extracted high-level features\n",
    "    imgs_features = feature_extractor(input_imgs)\n",
    "    \n",
    "    # initializers required by TensorFlow Hub\n",
    "    init_op = tf.group(\n",
    "        [tf.global_variables_initializer(), tf.tables_initializer()]\n",
    "    )\n",
    "\n",
    "img_graph.finalize() # make graph read-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbfb254-2486-40a3-a11f-3124ac1fecef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
